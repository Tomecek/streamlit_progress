{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d2417f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.utils import resample\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def load_data(success_path, failed_path):\n",
    "    # Load only genuine logs\n",
    "    success_df = pd.read_csv(success_path)\n",
    "    failed_df = pd.read_csv(failed_path)\n",
    "    \n",
    "    # Clean and label\n",
    "    success_df['label'] = 1  # LOGIN_SUCCESS\n",
    "    failed_df['label'] = 0   # LOGIN_FAILED\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    df = pd.concat([success_df, failed_df]).sample(frac=1, random_state=42)\n",
    "    \n",
    "    # Basic normalization (preserve key patterns)\n",
    "    def normalize(log):\n",
    "        log = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', '[IP]', log)\n",
    "        log = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', log)\n",
    "        return log\n",
    "    \n",
    "    df['normalized_log'] = df['Log'].apply(normalize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f64cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35b22afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_datasets(df):\n",
    "    # Verify labels are numeric\n",
    "    assert df['label'].dtype in [int, np.int64], \"Labels must be numeric\"\n",
    "    \n",
    "    # Stratified split (simplified)\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=0.2, stratify=df['label'], random_state=42\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_df, test_size=0.125, stratify=train_df['label'], random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convert to Dataset\n",
    "    return DatasetDict({\n",
    "        'train': Dataset.from_pandas(train_df),\n",
    "        'validation': Dataset.from_pandas(val_df),\n",
    "        'test': Dataset.from_pandas(test_df)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1dcb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Custom loss function for class imbalance\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = (1 - pt)**self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            loss = self.alpha[targets] * loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,  # Increased\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=3e-5,  # Adjusted\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    save_strategy='steps',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1_FAILED',  # Focus on minority class\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    report_to='none',\n",
    "    gradient_accumulation_steps=2  # Helps with small batches\n",
    ")\n",
    "\n",
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"jackaduma/SecBERT\",\n",
    "        num_labels=3,\n",
    "        ignore_mismatched_sizes=False  # Changed from True!\n",
    "    )\n",
    "    # Initialize classifier properly\n",
    "    model.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
    "    model.classifier.bias.data.zero_()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41155a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, AutoTokenizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jackaduma/SecBERT\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"normalized_log\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Add numeric labels to tokenized output\n",
    "    tokenized[\"labels\"] = examples[\"label\"]  \n",
    "    return tokenized\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Ensure labels are numeric\n",
    "    if isinstance(labels[0], str):\n",
    "        label_map = {\"OTHER\": 0, \"LOGIN_FAILED\": 1, \"LOGIN_SUCCESS\": 2}\n",
    "        labels = np.array([label_map[l] for l in labels])\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=None, labels=[0, 1, 2]\n",
    "    )\n",
    "    return {\n",
    "        'precision_OTHER': precision[0],\n",
    "        'recall_OTHER': recall[0],\n",
    "        'f1_OTHER': f1[0],\n",
    "        'precision_FAILED': precision[1],\n",
    "        'recall_FAILED': recall[1],\n",
    "        'f1_FAILED': f1[1],\n",
    "        'precision_SUCCESS': precision[2],\n",
    "        'recall_SUCCESS': recall[2],\n",
    "        'f1_SUCCESS': f1[2],\n",
    "    }\n",
    "\n",
    "def fine_tune(dataset):\n",
    "    # Tokenize datasets (now includes labels)\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5e3d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(trainer, dataset):\n",
    "    # Tokenize test set (with labels)\n",
    "    tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = trainer.predict(tokenized_test)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    \n",
    "    # Get true labels (ensure numeric)\n",
    "    true_labels = dataset[\"test\"][\"label\"]\n",
    "    if isinstance(true_labels[0], str):\n",
    "        label_map = {\"OTHER\": 0, \"LOGIN_FAILED\": 1, \"LOGIN_SUCCESS\": 2}\n",
    "        true_labels = [label_map[l] for l in true_labels]\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_labels, preds)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', \n",
    "                xticklabels=['OTHER', 'LOGIN_FAILED', 'LOGIN_SUCCESS'],\n",
    "                yticklabels=['OTHER', 'LOGIN_FAILED', 'LOGIN_SUCCESS'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report\n",
    "    print(classification_report(\n",
    "        true_labels, preds,\n",
    "        target_names=['OTHER', 'LOGIN_FAILED', 'LOGIN_SUCCESS']\n",
    "    ))\n",
    "    \n",
    "    # K-fold validation (updated)\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # Ensure df has numeric labels\n",
    "    df = dataset[\"train\"].to_pandas()\n",
    "    if isinstance(df['label'].iloc[0], str):\n",
    "        df['label'] = df['label'].map({\"OTHER\": 0, \"LOGIN_FAILED\": 1, \"LOGIN_SUCCESS\": 2})\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['label'])):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        fold_train = Dataset.from_pandas(df.iloc[train_idx])\n",
    "        fold_val = Dataset.from_pandas(df.iloc[val_idx])\n",
    "        \n",
    "        fold_trainer = fine_tune(DatasetDict({\n",
    "            'train': fold_train,\n",
    "            'validation': fold_val,\n",
    "            'test': fold_val  # Using val as test for fold evaluation\n",
    "        }))\n",
    "        evaluate_model(fold_trainer, DatasetDict({\n",
    "            'test': fold_val\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1644261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "def deploy_model(model_path, batch_size=32):\n",
    "    # Load best model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    \n",
    "    # Create pipeline with batching\n",
    "    classifier = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    def predict_logs(log_lines):\n",
    "        results = classifier(log_lines)\n",
    "        return [{\n",
    "            'label': result['label'],\n",
    "            'score': result['score'],\n",
    "            'log': log_lines[i]\n",
    "        } for i, result in enumerate(results)]\n",
    "    \n",
    "    # Example quantization (PyTorch only)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.half()  # FP16 quantization\n",
    "        \n",
    "    return predict_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5174c5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 280/280 [00:00<00:00, 6939.70 examples/s]\n",
      "Map: 100%|██████████| 40/40 [00:00<00:00, 3466.15 examples/s]\n",
      "Map: 100%|██████████| 80/80 [00:00<00:00, 5677.09 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at jackaduma/SecBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at jackaduma/SecBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 80/80 [00:00<00:00, 5680.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Tomas\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Tomas\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        OTHER       0.49      0.97      0.66        40\n",
      " LOGIN_FAILED       0.00      0.00      0.00        20\n",
      "LOGIN_SUCCESS       0.00      0.00      0.00        20\n",
      "\n",
      "     accuracy                           0.49        80\n",
      "    macro avg       0.16      0.33      0.22        80\n",
      " weighted avg       0.25      0.49      0.33        80\n",
      "\n",
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Field \"__index_level_0__\" exists 2 times in schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m fine_tune(dataset)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 5. Evaluate\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 6. Save best model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_secbert_login_classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[62], line 46\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(trainer, dataset)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(df, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     fold_train \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     fold_val \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(df\u001b[38;5;241m.\u001b[39miloc[val_idx])\n\u001b[0;32m     49\u001b[0m     fold_trainer \u001b[38;5;241m=\u001b[39m fine_tune(DatasetDict({\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: fold_train,\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m: fold_val,\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: fold_val  \u001b[38;5;66;03m# Using val as test for fold evaluation\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     }))\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:849\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[1;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[0;32m    848\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n\u001b[1;32m--> 849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:677\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, arrow_table, info, split, indices_table, fingerprint)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# In case there are types like pa.dictionary that we need to convert to the underlying type\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39marrow_schema:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrow_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# Infer fingerprint if None\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fingerprint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\table.py:860\u001b[0m, in \u001b[0;36mInMemoryTable.cast\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcast\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    848\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m    Cast table values to another schema.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;124;03m        `datasets.table.Table`\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InMemoryTable(\u001b[43mtable_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\table.py:2293\u001b[0m, in \u001b[0;36mtable_cast\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Improved version of `pa.Table.cast`.\u001b[39;00m\n\u001b[0;32m   2280\u001b[0m \n\u001b[0;32m   2281\u001b[0m \u001b[38;5;124;03mIt supports casting to feature types stored in the schema metadata.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;124;03m    table (`pyarrow.Table`): the casted table\u001b[39;00m\n\u001b[0;32m   2291\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m schema:\n\u001b[1;32m-> 2293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast_table_to_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m!=\u001b[39m schema\u001b[38;5;241m.\u001b[39mmetadata:\n\u001b[0;32m   2295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mreplace_schema_metadata(schema\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\table.py:2248\u001b[0m, in \u001b[0;36mcast_table_to_schema\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_column_names \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(schema\u001b[38;5;241m.\u001b[39mnames):\n\u001b[0;32m   2241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CastError(\n\u001b[0;32m   2242\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(table\u001b[38;5;241m.\u001b[39mschema)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbecause column names don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2243\u001b[0m         table_column_names\u001b[38;5;241m=\u001b[39mtable\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[0;32m   2244\u001b[0m         requested_column_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(features),\n\u001b[0;32m   2245\u001b[0m     )\n\u001b[0;32m   2246\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2247\u001b[0m     cast_array_to_feature(\n\u001b[1;32m-> 2248\u001b[0m         \u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m table_column_names \u001b[38;5;28;01melse\u001b[39;00m pa\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(table), \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mschema\u001b[38;5;241m.\u001b[39mfield(name)\u001b[38;5;241m.\u001b[39mtype),\n\u001b[0;32m   2249\u001b[0m         feature,\n\u001b[0;32m   2250\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2252\u001b[0m ]\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\table.pxi:1707\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular.__getitem__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\table.pxi:1793\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular.column\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\table.pxi:1732\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular._ensure_integer_index\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Field \"__index_level_0__\" exists 2 times in schema'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Prepare data\n",
    "    df = load_and_label_data(\"failed_login_logs.csv\", \"failed_login_logs.csv\")\n",
    "    \n",
    "    # 2. Create datasets\n",
    "    dataset = create_datasets(df)\n",
    "    \n",
    "    # 3-4. Fine-tune modeldata/sample-logs/failed_login_logs.csv data/sample-logs/successful_login_logs.csv\n",
    "    trainer = fine_tune(dataset)\n",
    "    \n",
    "    # 5. Evaluate\n",
    "    evaluate_model(trainer, dataset)\n",
    "    \n",
    "    # 6. Save best model\n",
    "    trainer.save_model(\"best_secbert_login_classifier\")\n",
    "    \n",
    "    # 7. Example deployment\n",
    "    predictor = deploy_model(\"best_secbert_login_classifier\")\n",
    "    sample_logs = [\"Failed login attempt from 192.168.1.1\", \"User admin logged in successfully\"]\n",
    "    print(json.dumps(predictor(sample_logs), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c340666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "class LoginClassifier:\n",
    "    def __init__(self, confidence_threshold=0.7):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"jackaduma/SecBERT\",\n",
    "            num_labels=2\n",
    "        ).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"jackaduma/SecBERT\")\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "\n",
    "    def predict(self, logs):\n",
    "        inputs = self.tokenizer(\n",
    "            logs,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "        results = []\n",
    "        for i, log in enumerate(logs):\n",
    "            pred_class = np.argmax(probs[i])\n",
    "            confidence = probs[i][pred_class]\n",
    "\n",
    "            if confidence < self.confidence_threshold:\n",
    "                label = \"OTHER\"\n",
    "            else:\n",
    "                label = \"LOGIN_SUCCESS\" if pred_class == 1 else \"LOGIN_FAILED\"\n",
    "\n",
    "            results.append({\n",
    "                'log': log,\n",
    "                'prediction': label,\n",
    "                'confidence': float(confidence),\n",
    "                'probabilities': {\n",
    "                    'LOGIN_FAILED': float(probs[i][0]),\n",
    "                    'LOGIN_SUCCESS': float(probs[i][1])\n",
    "                }\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def train(self, df):\n",
    "        labels = df['label'].values\n",
    "\n",
    "        encodings = self.tokenizer(\n",
    "            df['normalized_log'].tolist(),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        class LoginDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, encodings, labels):\n",
    "                self.encodings = encodings\n",
    "                self.labels = labels\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                return {\n",
    "                    'input_ids': self.encodings['input_ids'][idx],\n",
    "                    'attention_mask': self.encodings['attention_mask'][idx],\n",
    "                    'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "                }\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.labels)\n",
    "\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            range(len(df)), \n",
    "            test_size=0.2, \n",
    "            stratify=labels\n",
    "        )\n",
    "\n",
    "        train_dataset = LoginDataset(\n",
    "            {k: v[train_idx] for k, v in encodings.items()},\n",
    "            labels[train_idx]\n",
    "        )\n",
    "        val_dataset = LoginDataset(\n",
    "            {k: v[val_idx] for k, v in encodings.items()},\n",
    "            labels[val_idx]\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            num_train_epochs=3,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=64,\n",
    "            eval_strategy=\"epoch\",\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=10,\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            fp16=self.device.type == 'cuda'\n",
    "        )\n",
    "\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            preds = np.argmax(logits, axis=-1)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                labels, preds, average=None, labels=[0, 1]\n",
    "            )\n",
    "            return {\n",
    "                'f1_failed': float(f1[0]),\n",
    "                'f1_success': float(f1[1]),\n",
    "                'precision_failed': float(precision[0]),\n",
    "                'precision_success': float(precision[1])\n",
    "            }\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6520e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at jackaduma/SecBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Failed</th>\n",
       "      <th>F1 Success</th>\n",
       "      <th>Precision Failed</th>\n",
       "      <th>Precision Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>0.451369</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.088420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.039856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGIN_SUCCESS (0.80): User admin logged in successfully\n",
      "Probabilities: {'LOGIN_FAILED': 0.20236435532569885, 'LOGIN_SUCCESS': 0.7976356148719788}\n",
      "\n",
      "LOGIN_SUCCESS (0.86): Failed login attempt for user hacker\n",
      "Probabilities: {'LOGIN_FAILED': 0.1399831771850586, 'LOGIN_SUCCESS': 0.8600167632102966}\n",
      "\n",
      "OTHER (0.67): System reboot initiated\n",
      "Probabilities: {'LOGIN_FAILED': 0.329149067401886, 'LOGIN_SUCCESS': 0.6708508729934692}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "classifier = LoginClassifier()\n",
    "\n",
    "# Load data (assuming you have this function)\n",
    "df = load_data(\"successful_login_logs.csv\", \"failed_login_logs.csv\")\n",
    "\n",
    "# Train\n",
    "classifier.train(df)  # Corrected to use the instance method\n",
    "\n",
    "# Predict\n",
    "logs = [\n",
    "    \"User admin logged in successfully\",\n",
    "    \"Failed login attempt for user hacker\",\n",
    "    \"System reboot initiated\"\n",
    "]\n",
    "results = classifier.predict(logs)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result['prediction']} ({result['confidence']:.2f}): {result['log']}\")\n",
    "    print(f\"Probabilities: {result['probabilities']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8cc0e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGIN_FAILED (0.85): May 18 09:05:23 ubuntu sshd[3456]: Accepted password for user1\n",
      "Probabilities: {'LOGIN_FAILED': 0.8524448275566101, 'LOGIN_SUCCESS': 0.1475551873445511}\n",
      "\n",
      "LOGIN_SUCCESS (0.75): {\"eventTime\":\"2025-05-18T09:20:55Z\",\"eventName\":\"ConsoleLogin\",\"responseElements\":{\"ConsoleLogin\":\"Success\"}}\n",
      "Probabilities: {'LOGIN_FAILED': 0.2548333704471588, 'LOGIN_SUCCESS': 0.7451666593551636}\n",
      "\n",
      "LOGIN_SUCCESS (0.93): 2025-05-18T10:00:01Z Windows Server: EventID=4625 Authentication failed\n",
      "Probabilities: {'LOGIN_FAILED': 0.06566473096609116, 'LOGIN_SUCCESS': 0.9343352913856506}\n",
      "\n",
      "OTHER (0.59): {\"eventTime\":\"2025-05-18T10:25:56Z\",\"responseElements\":{\"ConsoleLogin\":\"Failure\"}}\n",
      "Probabilities: {'LOGIN_FAILED': 0.5867300629615784, 'LOGIN_SUCCESS': 0.41326993703842163}\n",
      "\n",
      "LOGIN_SUCCESS (0.96): {\"published\":\"2025-05-18T11:40:29Z\",\"eventType\":\"user.repository.delete\",\"outcome\":{\"result\":\"SUCCESS\"}}\n",
      "Probabilities: {'LOGIN_FAILED': 0.0427621528506279, 'LOGIN_SUCCESS': 0.9572377800941467}\n",
      "\n",
      "LOGIN_SUCCESS (0.90): 2025-05-18 12:10:00 Fortinet FortiGate: system_reboot_initiated\n",
      "Probabilities: {'LOGIN_FAILED': 0.09628009796142578, 'LOGIN_SUCCESS': 0.9037198424339294}\n",
      "\n",
      "OTHER (0.61): This is not a security log at all\n",
      "Probabilities: {'LOGIN_FAILED': 0.3895646631717682, 'LOGIN_SUCCESS': 0.6104353070259094}\n",
      "\n",
      "OTHER (0.62): 12424\n",
      "Probabilities: {'LOGIN_FAILED': 0.3847098648548126, 'LOGIN_SUCCESS': 0.6152901649475098}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_logs = [\n",
    "        # Successful logins\n",
    "        \"May 18 09:05:23 ubuntu sshd[3456]: Accepted password for user1\",\n",
    "        '{\"eventTime\":\"2025-05-18T09:20:55Z\",\"eventName\":\"ConsoleLogin\",\"responseElements\":{\"ConsoleLogin\":\"Success\"}}',\n",
    "        # Failed logins\n",
    "        \"2025-05-18T10:00:01Z Windows Server: EventID=4625 Authentication failed\",\n",
    "        '{\"eventTime\":\"2025-05-18T10:25:56Z\",\"responseElements\":{\"ConsoleLogin\":\"Failure\"}}',\n",
    "        # Other events\n",
    "        '{\"published\":\"2025-05-18T11:40:29Z\",\"eventType\":\"user.repository.delete\",\"outcome\":{\"result\":\"SUCCESS\"}}',\n",
    "        \"2025-05-18 12:10:00 Fortinet FortiGate: system_reboot_initiated\",\n",
    "        # Edge cases\n",
    "        \"This is not a security log at all\",\n",
    "        \"12424\",\n",
    "    ]\n",
    "\n",
    "results = classifier.predict(test_logs)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result['prediction']} ({result['confidence']:.2f}): {result['log']}\")\n",
    "    print(f\"Probabilities: {result['probabilities']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3427c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
