{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b8cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Memory allocated: 2518.35 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training event classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 5/5 [00:42<00:00,  8.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train Loss: 1.0347\n",
      "Val Loss: 0.8907\n",
      "Val Accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5/5 [00:53<00:00, 10.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "Train Loss: 0.8761\n",
      "Val Loss: 0.7712\n",
      "Val Accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [02:06<00:00, 25.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "Train Loss: 0.7303\n",
      "Val Loss: 0.6589\n",
      "Val Accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [01:17<00:00, 15.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "Train Loss: 0.6394\n",
      "Val Loss: 0.5730\n",
      "Val Accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [01:21<00:00, 16.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "Train Loss: 0.5469\n",
      "Val Loss: 0.5161\n",
      "Val Accuracy: 0.7625\n",
      "\n",
      "Processing new logs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing logs:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-PER', 'score': 0.5425031, 'index': 11, 'word': '##jo', 'start': 24, 'end': 26}, {'entity': 'B-PER', 'score': 0.7847678, 'index': 12, 'word': '##hn', 'start': 26, 'end': 28}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.9532609, 'index': 1, 'word': 'ER', 'start': 0, 'end': 2}, {'entity': 'I-ORG', 'score': 0.93673354, 'index': 2, 'word': '##RO', 'start': 2, 'end': 4}, {'entity': 'I-ORG', 'score': 0.8225565, 'index': 3, 'word': '##R', 'start': 4, 'end': 5}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.9947536, 'index': 8, 'word': 'Lab', 'start': 16, 'end': 19}, {'entity': 'I-ORG', 'score': 0.97525024, 'index': 9, 'word': '##S', 'start': 19, 'end': 20}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing logs:  50%|█████     | 1/2 [00:01<00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.9931016, 'index': 8, 'word': 'Lab', 'start': 16, 'end': 19}, {'entity': 'I-ORG', 'score': 0.98801917, 'index': 9, 'word': '##S', 'start': 19, 'end': 20}, {'entity': 'I-ORG', 'score': 0.62680084, 'index': 10, 'word': '##Z', 'start': 20, 'end': 21}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.99323386, 'index': 8, 'word': 'Lab', 'start': 16, 'end': 19}, {'entity': 'I-ORG', 'score': 0.9883812, 'index': 9, 'word': '##S', 'start': 19, 'end': 20}, {'entity': 'I-ORG', 'score': 0.5991771, 'index': 10, 'word': '##Z', 'start': 20, 'end': 21}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.99341846, 'index': 8, 'word': 'Lab', 'start': 16, 'end': 19}, {'entity': 'I-ORG', 'score': 0.99155116, 'index': 9, 'word': '##S', 'start': 19, 'end': 20}, {'entity': 'I-ORG', 'score': 0.5445104, 'index': 10, 'word': '##Z', 'start': 20, 'end': 21}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing logs: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.99566793, 'index': 8, 'word': 'Lab', 'start': 16, 'end': 19}, {'entity': 'I-ORG', 'score': 0.9934236, 'index': 9, 'word': '##S', 'start': 19, 'end': 20}, {'entity': 'I-ORG', 'score': 0.73691124, 'index': 10, 'word': '##Z', 'start': 20, 'end': 21}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.99229336, 'index': 8, 'word': 'Lab', 'start': 16, 'end': 19}, {'entity': 'I-ORG', 'score': 0.9886895, 'index': 9, 'word': '##S', 'start': 19, 'end': 20}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.9947536, 'index': 8, 'word': 'Lab', 'start': 16, 'end': 19}, {'entity': 'I-ORG', 'score': 0.97525024, 'index': 9, 'word': '##S', 'start': 19, 'end': 20}]\n",
      "                                                                                                                                                  raw_log              event_type  confidence            timestamp        source_ip   status\n",
      "0                                                                    2023-05-16 09:15:33 - login failed for user jsmith from 10.1.2.3 with error AUTH-402            Failed_login    0.506849  2023-05-16T09:15:33         10.1.2.3  failure\n",
      "1                                                                        May 16 10:22:18 - user mjohnson attempted to use sudo command to install package                   Other    0.568471                 None              NaN      NaN\n",
      "2                                                                                   ERROR 2023-05-16 11:45:22: Disk utilization exceeded 95% on /dev/sdb1            Failed_login    0.604008  2023-05-16T11:45:22              NaN  failure\n",
      "3                                                       Dec 10 09:32:20 LabSZ sshd[24680]: Accepted password for fztu from 119.137.62.142 port 49116 ssh2  authentication_success    1.000000                 None   119.137.62.142  success\n",
      "4                                                                            WARNING: 5 consecutive authentication failures for user demo from 192.0.2.15            Failed_login    0.565029                 None       192.0.2.15      NaN\n",
      "5                                                                                2023-05-16 13:30:45 - connection refused from suspicious IP 198.51.100.7            Failed_login    0.580101  2023-05-16T13:30:45     198.51.100.7      NaN\n",
      "6                                                                                        2023-05-15 14:30:45 - login failed for user jsmith from 10.1.2.3           Success_login    0.489923  2023-05-15T14:30:45         10.1.2.3  failure\n",
      "7                                                                                            WARNING: 5 consecutive authentication failures for user demo            Failed_login    0.445275  2025-05-05T00:00:00              NaN      NaN\n",
      "8                        Jun 14 15:16:01 combo sshd(pam_unix)[19939]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4            Failed_login    0.668764                 None      218.188.2.4      NaN\n",
      "9                                                                                   Jun 14 15:16:02 combo sshd(pam_unix)[19937]: check pass; user unknown                   Other    0.869028  2025-06-14T15:16:02              NaN      NaN\n",
      "10                       Jun 14 15:16:02 combo sshd(pam_unix)[19937]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4            Failed_login    0.662785                 None      218.188.2.4      NaN\n",
      "11  Jun 15 02:04:59 combo sshd(pam_unix)[20882]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet....            Failed_login    0.725724                 None              NaN      NaN\n",
      "12  Jun 15 02:04:59 combo sshd(pam_unix)[20884]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet....            Failed_login    0.722276                 None              NaN      NaN\n",
      "13             Dec 10 07:11:42 LabSZ sshd[24224]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=202.100.179.208                   Other    0.824468                 None  202.100.179.208      NaN\n",
      "14                                          Dec 10 07:11:44 LabSZ sshd[24224]: Failed password for invalid user chen from 202.100.179.208 port 32484 ssh2  authentication_failure    1.000000                 None  202.100.179.208  failure\n",
      "15                                                     Dec 10 07:11:44 LabSZ sshd[24224]: Received disconnect from 202.100.179.208: 11: Bye Bye [preauth]  authentication_success    1.000000                 None  202.100.179.208      NaN\n",
      "16  Dec 10 07:13:31 LabSZ sshd[24227]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=5.36.59.76.dynamic-dsl-...                   Other    0.830000                 None       5.36.59.76      NaN\n",
      "17                                                            Dec 10 07:13:43 LabSZ sshd[24227]: Failed password for root from 5.36.59.76 port 42393 ssh2  authentication_failure    1.000000                 None       5.36.59.76  failure\n",
      "18                                                      Dec 10 09:32:20 LabSZ sshd[24680]: Accepted password for fztu from 119.137.62.142 port 49116 ssh2  authentication_success    1.000000                 None   119.137.62.142  success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "from dateutil import parser as date_parser\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "# dostupnost gpu + mem.\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "\n",
    "class LogDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for log data\"\"\"\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTLogOnboarder:\n",
    "    def __init__(self):\n",
    "        #inicializace samotného BERT\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.event_classifier = None\n",
    "        self.field_extractor = None\n",
    "        self.label_encoder = None\n",
    "        self.max_length = 128 # budu muset hodně omezovat kvůli max_memory 512 nedám a 256 už taky ne\n",
    "        \n",
    "        \n",
    "        #feature extraction pro logy (parsování) <-- moc nefunguje bude třeba samostatný a custom       \n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.ner_pipeline = pipeline(\n",
    "            \"ner\",\n",
    "            model=\"dslim/bert-base-NER\",\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        \n",
    "        self.common_events = self._load_common_event_patterns()\n",
    "        \n",
    "    def _load_common_event_patterns(self): #tohle ještě převedu do samostatného souboru\n",
    "        try:\n",
    "            with open('event_patterns##.json') as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            return {\n",
    "                'authentication_success': [\n",
    "                    \"accepted password for\",\n",
    "                    \"successful authentication\",\n",
    "                    \"login successful for\",\n",
    "                    \"authenticated successfully\"\n",
    "                ],\n",
    "                'authentication_failure': [\n",
    "                    \"login failed for user\",\n",
    "                    \"authentication failure\",\n",
    "                    \"invalid credentials\",\n",
    "                    \"failed password for\",\n",
    "                    \"authentication failure; logname=\"\n",
    "                ]\n",
    "            }\n",
    "    \n",
    "    def train_event_classifier(self, texts, labels, epochs=3, batch_size=32): #epochs= 3, batch_size=16\n",
    "        \"\"\"\n",
    "        Train BERT model for log event classification\n",
    "        :param texts: List of log texts\n",
    "        :param labels: List of string labels\n",
    "        :param epochs: Number of training epochs\n",
    "        :param batch_size: Batch size for training\n",
    "        \"\"\"\n",
    "        # labels\n",
    "        unique_labels = sorted(set(labels))\n",
    "        self.label_encoder = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.inv_label_encoder = {idx: label for label, idx in self.label_encoder.items()}\n",
    "        num_labels = len(unique_labels)\n",
    "        \n",
    "        # encode labels\n",
    "        encoded_labels = [self.label_encoder[label] for label in labels]\n",
    "        \n",
    "        # train test split klasicky\n",
    "        train_texts, val_texts, train_labels, val_labels = train_test_split(texts, encoded_labels, test_size=0.2, random_state=1337)\n",
    "        \n",
    "        #datasety\n",
    "        train_dataset = LogDataset(train_texts, train_labels, self.tokenizer, self.max_length)\n",
    "        val_dataset = LogDataset(val_texts, val_labels, self.tokenizer, self.max_length)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with correct number of labels\n",
    "        self.event_classifier = BertForSequenceClassification.from_pretrained(\n",
    "            'bert-base-uncased',\n",
    "            num_labels=num_labels\n",
    "        ).to(device)\n",
    "        \n",
    "        # training setup + trénovací loop\n",
    "        optimizer = torch.optim.AdamW(self.event_classifier.parameters(), lr=2e-5)\n",
    "        for epoch in range(epochs):\n",
    "            self.event_classifier.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = self.event_classifier(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # validace\n",
    "            self.event_classifier.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "                    \n",
    "                    outputs = self.event_classifier(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    \n",
    "                    val_loss += outputs.loss.item()\n",
    "                    _, predicted = torch.max(outputs.logits, 1)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}:\")\n",
    "            print(f\"Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "            print(f\"Val Loss: {val_loss / len(val_loader):.4f}\")\n",
    "            print(f\"Val Accuracy: {correct / total:.4f}\")\n",
    "    \n",
    "    def identify_event(self, log_line):\n",
    "        \"\"\"\n",
    "        Identify security-relevant events using BERT\n",
    "        :param log_line: Raw log text\n",
    "        :return: Detected event type and confidence\n",
    "        \"\"\"\n",
    "        # rule-based check paternu\n",
    "        for event_type, patterns in self.common_events.items():\n",
    "            for pattern in patterns:\n",
    "                if pattern.lower() in log_line.lower():\n",
    "                    return event_type, 1.0\n",
    "        \n",
    "        # použití Berta\n",
    "        if self.event_classifier:\n",
    "            encoding = self.tokenizer(\n",
    "                log_line,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            input_ids = encoding['input_ids'].to(device)\n",
    "            attention_mask = encoding['attention_mask'].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.event_classifier(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, dim=1)\n",
    "            \n",
    "            if self.label_encoder:\n",
    "                inv_label_encoder = {v: k for k, v in self.label_encoder.items()}\n",
    "                event_type = inv_label_encoder[predicted.item()]\n",
    "            else:\n",
    "                event_type = str(predicted.item())\n",
    "            \n",
    "            return event_type, confidence.item()\n",
    "        \n",
    "        return \"unknown\", 0.0\n",
    "    \n",
    "    def extract_fields_with_bert(self, log_line): # random paste NER od odborníka 🤓, ale tento je třeba udělat custom a odkazovat se na něj\n",
    "        \"\"\"\n",
    "        Enhanced field extraction using BERT NER and custom patterns\n",
    "        :param log_line: Raw log text\n",
    "        :return: Dictionary of extracted fields\n",
    "        \"\"\"\n",
    "        fields = {}\n",
    "    \n",
    "        # Timestamp extraction (keep existing)\n",
    "        fields['timestamp'] = self._extract_timestamp(log_line)\n",
    "        \n",
    "        # Enhanced IP extraction\n",
    "        ip_pattern = r'(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)'\n",
    "        ip_addresses = re.findall(ip_pattern, log_line)\n",
    "        if ip_addresses:\n",
    "            fields['source_ip'] = ip_addresses[0]\n",
    "        \n",
    "        # Enhanced username extraction\n",
    "        user_patterns = [\n",
    "            r'user\\s+([^\\s]+)',  # \"user jsmith\"\n",
    "            r'for\\s+user\\s+([^\\s]+)',  # \"for user admin\"\n",
    "            r'user=([^\\s]+)',  # \"user=root\"\n",
    "        ]\n",
    "        for pattern in user_patterns:\n",
    "            if match := re.search(pattern, log_line, re.IGNORECASE):\n",
    "                fields['username'] = match.group(1)\n",
    "                break\n",
    "        \n",
    "        # Use BERT NER for entity recognition\n",
    "        ner_results = self.ner_pipeline(log_line)\n",
    "        print(f\"Tohle je výstup z extract_fields_with_bert  aka ner_results-->{ner_results}\")\n",
    "        # Process NER results\n",
    "        for entity in ner_results:\n",
    "            if entity['entity'] == 'B-PER' or entity['entity'] == 'I-PER':\n",
    "                fields.setdefault('usernames', []).append(entity['word'])\n",
    "            elif entity['entity'] == 'B-ORG' or entity['entity'] == 'I-ORG':\n",
    "                fields.setdefault('organizations', []).append(entity['word'])\n",
    "            elif entity['entity'] == 'B-LOC' or entity['entity'] == 'I-LOC':\n",
    "                fields.setdefault('locations', []).append(entity['word'])\n",
    "        \n",
    "        # Extract error codes\n",
    "        error_codes = re.findall(r'\\b[A-Z]{2,5}-\\d{3,5}\\b', log_line)\n",
    "        if error_codes:\n",
    "            fields['error_code'] = error_codes[0]\n",
    "        \n",
    "        # Extract status indicators\n",
    "        status_keywords = {\n",
    "            'failed': 'failure',\n",
    "            'accepted': 'success',\n",
    "            'error': 'failure',\n",
    "            'success': 'success',\n",
    "            'completed': 'success',\n",
    "            'denied': 'failure',\n",
    "            'blocked': 'failure'\n",
    "        }\n",
    "        \n",
    "        for keyword, status in status_keywords.items():\n",
    "            if keyword in log_line.lower():\n",
    "                fields['status'] = status\n",
    "                break\n",
    "        \n",
    "        # Use spaCy for additional parsing\n",
    "        doc = self.nlp(log_line)\n",
    "        \n",
    "        # Extract verbs as potential actions\n",
    "        fields['actions'] = [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
    "        \n",
    "        # Extract numbers that might be counts or IDs\n",
    "        fields['numbers'] = [ent.text for ent in doc.ents if ent.label_ == \"CARDINAL\"]\n",
    "        \n",
    "        return fields\n",
    "    \n",
    "    @lru_cache(maxsize=1000)\n",
    "    def _extract_timestamp(self, text):\n",
    "        \"\"\"Enhanced timestamp extraction with multiple strategies\"\"\"\n",
    "        # Try common log timestamp formats first\n",
    "        common_formats = [\n",
    "            r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',\n",
    "            r'\\d{2}/\\d{2}/\\d{4} \\d{2}:\\d{2}:\\d{2}',\n",
    "            r'[A-Z][a-z]{2} \\d{2} \\d{4} \\d{2}:\\d{2}:\\d{2}',\n",
    "            r'\\d{10}',  # Unix timestamp\n",
    "            r'\\d{13}',  # Unix timestamp with milliseconds\n",
    "        ]\n",
    "        \n",
    "        for fmt in common_formats:\n",
    "            match = re.search(fmt, text)\n",
    "            if match:\n",
    "                try:\n",
    "                    return date_parser.parse(match.group(0)).isoformat()\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Fallback to dateutil's fuzzy parsing\n",
    "        try:\n",
    "            return date_parser.parse(text, fuzzy=True).isoformat()\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def process_logs(self, log_lines, batch_size=16):\n",
    "        results = []\n",
    "        \n",
    "        # processování btache logů\n",
    "        for i in tqdm(range(0, len(log_lines), batch_size), desc=\"Processing logs\"):\n",
    "            batch = log_lines[i:i + batch_size]\n",
    "            \n",
    "            for line in batch:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                    \n",
    "                event_type, confidence = self.identify_event(line)\n",
    "                fields = self.extract_fields_with_bert(line)\n",
    "                \n",
    "                result = {\n",
    "                    'raw_log': line,\n",
    "                    'event_type': event_type,\n",
    "                    'confidence': confidence,\n",
    "                    **fields\n",
    "                }\n",
    "                results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train_data = pd.read_csv(\"../data/train-logs/df_400logs.csv\")\n",
    "    labeled_data = {\n",
    "        'texts': train_data['text'].tolist(),\n",
    "        'labels': train_data['label'].tolist()\n",
    "    }\n",
    "    \n",
    "    onboarder = BERTLogOnboarder()\n",
    "    \n",
    "    # trénovačřka\n",
    "    print(\"Training event classifier...\")\n",
    "    onboarder.train_event_classifier(labeled_data['texts'], labeled_data['labels'], epochs=5, batch_size=64)\n",
    "    \n",
    "    # Process new logs\n",
    "    new_logs = [\n",
    "        \"2023-05-16 09:15:33 - login failed for user jsmith from 10.1.2.3 with error AUTH-402\",\n",
    "        \"May 16 10:22:18 - user mjohnson attempted to use sudo command to install package\",\n",
    "        \"ERROR 2023-05-16 11:45:22: Disk utilization exceeded 95% on /dev/sdb1\",\n",
    "        \"Dec 10 09:32:20 LabSZ sshd[24680]: Accepted password for fztu from 119.137.62.142 port 49116 ssh2\",\n",
    "        \"WARNING: 5 consecutive authentication failures for user demo from 192.0.2.15\",\n",
    "        \"2023-05-16 13:30:45 - connection refused from suspicious IP 198.51.100.7\",\n",
    "        \"2023-05-15 14:30:45 - login failed for user jsmith from 10.1.2.3\",\n",
    "        \"WARNING: 5 consecutive authentication failures for user demo\",\n",
    "        \"Jun 14 15:16:01 combo sshd(pam_unix)[19939]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4\", \n",
    "        \"Jun 14 15:16:02 combo sshd(pam_unix)[19937]: check pass; user unknown\",\n",
    "        \"Jun 14 15:16:02 combo sshd(pam_unix)[19937]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4\",\n",
    "        \"Jun 15 02:04:59 combo sshd(pam_unix)[20882]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet.net  user=root\",\n",
    "        \"Jun 15 02:04:59 combo sshd(pam_unix)[20884]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet.net  user=roo\",\n",
    "        \"Dec 10 07:11:42 LabSZ sshd[24224]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=202.100.179.208\",\n",
    "        \"Dec 10 07:11:44 LabSZ sshd[24224]: Failed password for invalid user chen from 202.100.179.208 port 32484 ssh2\",\n",
    "        \"Dec 10 07:11:44 LabSZ sshd[24224]: Received disconnect from 202.100.179.208: 11: Bye Bye [preauth]\",\n",
    "        \"Dec 10 07:13:31 LabSZ sshd[24227]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=5.36.59.76.dynamic-dsl-ip.omantel.net.om  user=root\",\n",
    "        \"Dec 10 07:13:43 LabSZ sshd[24227]: Failed password for root from 5.36.59.76 port 42393 ssh2\",\n",
    "        \"Dec 10 09:32:20 LabSZ sshd[24680]: Accepted password for fztu from 119.137.62.142 port 49116 ssh2\",\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nProcessing new logs...\")\n",
    "    processed_logs = onboarder.process_logs(new_logs)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_colwidth', 150)\n",
    "    print(processed_logs[['raw_log', 'event_type', 'confidence', 'timestamp', 'source_ip', 'status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a012e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing new logs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing logs:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.88491935, 'index': 15, 'word': 'Windows', 'start': 21, 'end': 28}, {'entity': 'I-MISC', 'score': 0.9660503, 'index': 16, 'word': 'Server', 'start': 29, 'end': 35}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.7843622, 'index': 12, 'word': 'mac', 'start': 20, 'end': 23}, {'entity': 'I-MISC', 'score': 0.8377228, 'index': 13, 'word': '##OS', 'start': 23, 'end': 25}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.87390125, 'index': 12, 'word': 'C', 'start': 20, 'end': 21}, {'entity': 'B-ORG', 'score': 0.663588, 'index': 13, 'word': '##isco', 'start': 21, 'end': 25}, {'entity': 'I-MISC', 'score': 0.7831019, 'index': 14, 'word': 'AS', 'start': 26, 'end': 28}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.8979027, 'index': 14, 'word': 'Windows', 'start': 21, 'end': 28}, {'entity': 'I-MISC', 'score': 0.9771548, 'index': 15, 'word': 'Server', 'start': 29, 'end': 35}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.8124715, 'index': 12, 'word': 'mac', 'start': 20, 'end': 23}, {'entity': 'I-MISC', 'score': 0.90264803, 'index': 13, 'word': '##OS', 'start': 23, 'end': 25}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.7352358, 'index': 12, 'word': 'C', 'start': 20, 'end': 21}, {'entity': 'B-ORG', 'score': 0.48406392, 'index': 13, 'word': '##isco', 'start': 21, 'end': 25}, {'entity': 'I-MISC', 'score': 0.6830215, 'index': 14, 'word': 'AS', 'start': 26, 'end': 28}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.9187101, 'index': 57, 'word': 'A', 'start': 100, 'end': 101}, {'entity': 'B-MISC', 'score': 0.9266694, 'index': 58, 'word': '##zure', 'start': 101, 'end': 105}, {'entity': 'I-MISC', 'score': 0.9005259, 'index': 59, 'word': 'Portal', 'start': 106, 'end': 112}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing logs:  50%|█████     | 1/2 [00:01<00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.9656732, 'index': 44, 'word': 'O', 'start': 86, 'end': 87}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.86809117, 'index': 14, 'word': 'Windows', 'start': 21, 'end': 28}, {'entity': 'I-MISC', 'score': 0.9737371, 'index': 15, 'word': 'Server', 'start': 29, 'end': 35}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.79285204, 'index': 12, 'word': 'mac', 'start': 20, 'end': 23}, {'entity': 'I-MISC', 'score': 0.9040378, 'index': 13, 'word': '##OS', 'start': 23, 'end': 25}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-ORG', 'score': 0.6532236, 'index': 12, 'word': 'C', 'start': 20, 'end': 21}, {'entity': 'I-MISC', 'score': 0.7491876, 'index': 14, 'word': 'AS', 'start': 26, 'end': 28}, {'entity': 'I-MISC', 'score': 0.5221594, 'index': 19, 'word': '##A', 'start': 34, 'end': 35}]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n",
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing logs: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tohle je výstup z extract_fields_with_bert  aka ner_results-->[{'entity': 'B-MISC', 'score': 0.5699082, 'index': 12, 'word': 'Fort', 'start': 20, 'end': 24}]\n",
      "                                                                                                                                                  raw_log              event_type  confidence                  timestamp   status\n",
      "0                                                     2025-05-18T09:00:12Z Windows Server: EventID=4624 Authentication granted for user021 IP=192.0.2.200           Success_login    0.526447                       None      NaN\n",
      "1                                                          May 18 09:05:23 ubuntu sshd[3456]: Access granted for user022 from 192.0.2.201 port 56321 ssh2            Failed_login    0.487361                       None      NaN\n",
      "2                                                              2025-05-18 09:10:45 macOS loginwindow[6001]: Sign-in successful for user user023 (UID 560)           Success_login    0.526178        2025-05-18T09:10:45  success\n",
      "3                       2025-05-18 09:15:30 Cisco ASA: %ASA-6-722051: VPN Connection: credentials accepted: User=user024 IP=192.0.2.202 Duration=00:05:00           Success_login    0.478543        2025-05-18T09:15:30  success\n",
      "4   {\"eventTime\":\"2025-05-18T09:20:55Z\",\"eventName\":\"ConsoleLogin\",\"userIdentity\":{\"type\":\"IAMUser\",\"userName\":\"user025\"},\"sourceIPAddress\":\"192.0.2.2...           Success_login    0.567356                       None  success\n",
      "5                                                      2025-05-18T10:00:01Z Windows Server: EventID=4625 Authentication failed for user026 IP=192.0.2.204           Success_login    0.482068                       None  failure\n",
      "6                                                           May 18 10:05:12 ubuntu sshd[3567]: Access denied for user027 from 192.0.2.205 port 57322 ssh2  authentication_failure    1.000000                       None  failure\n",
      "7                                                                  2025-05-18 10:10:23 macOS loginwindow[6002]: Sign-in denied for user user028 (UID 561)           Success_login    0.483158        2025-05-18T10:10:23  failure\n",
      "8                2025-05-18 10:15:34 Cisco ASA: %ASA-6-722051: VPN Connection: authentication unsuccessful: User=user029 IP=192.0.2.206 Duration=00:00:30            Failed_login    0.524073        2025-05-18T10:15:34  success\n",
      "9     2025/05/18 10:20:45,001801000014,SYSTEM,gplogin,0,2025/05/18 10:20:45,192.0.2.207,10.0.0.2,Login,globalprotect,user=user030,tunnel=no,result=denied           Success_login    0.540532                       None  failure\n",
      "10  {\"eventTime\":\"2025-05-18T10:25:56Z\",\"eventName\":\"ConsoleLogin\",\"userIdentity\":{\"type\":\"IAMUser\",\"userName\":\"user031\"},\"sourceIPAddress\":\"192.0.2.2...           Success_login    0.562973                       None      NaN\n",
      "11  {\"TimeGenerated\":\"2025-05-18T10:30:07Z\",\"UserPrincipalName\":\"user032@example.com\",\"AppDisplayName\":\"Azure Portal\",\"Status\":{\"value\":\"1\",\"additiona...           Success_login    0.572879                       None      NaN\n",
      "12                  timestamp=2025-05-18T10:35:18Z event=login login_type=authorized principal=user033@example.com ip_address=192.0.2.210 outcome=FAILURE  authentication_failure    1.000000                       None      NaN\n",
      "13  {\"published\":\"2025-05-18T10:40:29Z\",\"eventType\":\"user.session.start\",\"outcome\":{\"result\":\"DENIED\"},\"actor\":{\"displayName\":\"user034\"},\"client\":{\"ip...           Success_login    0.575990                       None  failure\n",
      "14                                                            2025-05-18T10:45:40,user035@example.com,Login,login.salesforce.com,Failed,192.0.2.212,OAuth           Success_login    0.491020                       None  failure\n",
      "15                                                                              2025-05-18T11:00:00Z Windows Server: EventID=4647 User logoff for user021           Success_login    0.550639                       None      NaN\n",
      "16                                                                                          May 18 11:05:12 ubuntu sshd[4000]: session closed for user022            Failed_login    0.537790        2022-05-18T11:05:12      NaN\n",
      "17                                                                    2025-05-18 11:10:23 macOS loginwindow[6003]: User logout for user user023 (UID 562)           Success_login    0.494268        2025-05-18T11:10:23      NaN\n",
      "18                                                2025-05-18 11:15:34 Cisco ASA: %ASA-6-722052: VPN Logout: User=user024 IP=192.0.2.202 Duration=00:05:10           Success_login    0.482523        2025-05-18T11:15:34      NaN\n",
      "19                2025/05/18 11:20:45,001801000015,SYSTEM,gplogin,0,2025/05/18 11:20:45,192.0.2.207,10.0.0.2,Logout,globalprotect,user=user026,tunnel=yes           Success_login    0.540025                       None      NaN\n",
      "20  {\"eventTime\":\"2025-05-18T11:25:56Z\",\"eventName\":\"ModifyUser\",\"userIdentity\":{\"type\":\"IAMUser\",\"userName\":\"user027\"},\"sourceIPAddress\":\"192.0.2.208...           Success_login    0.565104                       None      NaN\n",
      "21                           {\"TimeGenerated\":\"2025-05-18T11:30:07Z\",\"Operation\":\"UserLoggedOut\",\"UserId\":\"user028@example.com\",\"ClientIP\":\"192.0.2.209\"}           Success_login    0.555598                       None      NaN\n",
      "22                                                       timestamp=2025-05-18T11:35:18Z event=logout principal=user029@example.com ip_address=192.0.2.210           Success_login    0.513030                       None      NaN\n",
      "23  {\"published\":\"2025-05-18T11:40:29Z\",\"eventType\":\"user.repository.delete\",\"outcome\":{\"result\":\"SUCCESS\"},\"actor\":{\"displayName\":\"user030\"},\"client\"...           Success_login    0.579209                       None  success\n",
      "24                                                                  2025-05-18T11:45:40,user031@example.com,API,updateRecord,login.salesforce.com,Success           Success_login    0.561737                       None  success\n",
      "25    {\"CreationTime\":\"2025-05-18T11:50:00\",\"Operation\":\"FileDownloaded\",\"UserId\":\"user032@example.com\",\"ClientIP\":\"192.0.2.212\",\"ItemName\":\"report.pdf\"}           Success_login    0.556087                       None      NaN\n",
      "26                                      2025-05-18T11:55:00 UTC [3900]: [user033]@hrdb LOG:  statement: SELECT * FROM employees WHERE department='Sales';            Failed_login    0.484303  2025-05-18T11:55:00+00:00      NaN\n",
      "27                                                2025-05-18T12:00:00Z 50 Query user034@192.0.2.213 on payrolldb: execute UPDATE payroll SET amount=5000;           Success_login    0.479502                       None      NaN\n",
      "28                                                        192.0.2.91 - - [18/May/2025:12:05:00 +0000] \"GET /api/data HTTP/1.1\" 200 1285 \"-\" \"curl/7.68.0\"           Success_login    0.542509                       None      NaN\n",
      "29        2025-05-18 12:10:00 Fortinet FortiGate device_id=FGT002 log_id=0100030001 type=event subtype=system level=notice action=system_reboot_initiated           Success_login    0.508385        2025-05-18T12:10:00      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_logs_bert = [\n",
    "    # 5 successful login events\n",
    "    \"2025-05-18T09:00:12Z Windows Server: EventID=4624 Authentication granted for user021 IP=192.0.2.200\",\n",
    "    \"May 18 09:05:23 ubuntu sshd[3456]: Access granted for user022 from 192.0.2.201 port 56321 ssh2\",\n",
    "    \"2025-05-18 09:10:45 macOS loginwindow[6001]: Sign-in successful for user user023 (UID 560)\",\n",
    "    \"2025-05-18 09:15:30 Cisco ASA: %ASA-6-722051: VPN Connection: credentials accepted: User=user024 IP=192.0.2.202 Duration=00:05:00\",\n",
    "    '{\"eventTime\":\"2025-05-18T09:20:55Z\",\"eventName\":\"ConsoleLogin\",\"userIdentity\":{\"type\":\"IAMUser\",\"userName\":\"user025\"},\"sourceIPAddress\":\"192.0.2.203\",\"responseElements\":{\"ConsoleLogin\":\"Success\"}}',\n",
    "\n",
    "    # 10 failed login attempts\n",
    "    \"2025-05-18T10:00:01Z Windows Server: EventID=4625 Authentication failed for user026 IP=192.0.2.204\",\n",
    "    \"May 18 10:05:12 ubuntu sshd[3567]: Access denied for user027 from 192.0.2.205 port 57322 ssh2\",\n",
    "    \"2025-05-18 10:10:23 macOS loginwindow[6002]: Sign-in denied for user user028 (UID 561)\",\n",
    "    \"2025-05-18 10:15:34 Cisco ASA: %ASA-6-722051: VPN Connection: authentication unsuccessful: User=user029 IP=192.0.2.206 Duration=00:00:30\",\n",
    "    \"2025/05/18 10:20:45,001801000014,SYSTEM,gplogin,0,2025/05/18 10:20:45,192.0.2.207,10.0.0.2,Login,globalprotect,user=user030,tunnel=no,result=denied\",\n",
    "    '{\"eventTime\":\"2025-05-18T10:25:56Z\",\"eventName\":\"ConsoleLogin\",\"userIdentity\":{\"type\":\"IAMUser\",\"userName\":\"user031\"},\"sourceIPAddress\":\"192.0.2.208\",\"responseElements\":{\"ConsoleLogin\":\"Failure\"}}',\n",
    "    '{\"TimeGenerated\":\"2025-05-18T10:30:07Z\",\"UserPrincipalName\":\"user032@example.com\",\"AppDisplayName\":\"Azure Portal\",\"Status\":{\"value\":\"1\",\"additionalDetails\":\"Failure\"},\"IPAddress\":\"192.0.2.209\"}',\n",
    "    \"timestamp=2025-05-18T10:35:18Z event=login login_type=authorized principal=user033@example.com ip_address=192.0.2.210 outcome=FAILURE\",\n",
    "    '{\"published\":\"2025-05-18T10:40:29Z\",\"eventType\":\"user.session.start\",\"outcome\":{\"result\":\"DENIED\"},\"actor\":{\"displayName\":\"user034\"},\"client\":{\"ipAddress\":\"192.0.2.211\"}}',\n",
    "    \"2025-05-18T10:45:40,user035@example.com,Login,login.salesforce.com,Failed,192.0.2.212,OAuth\",\n",
    "\n",
    "    # 15 other types of events\n",
    "    \"2025-05-18T11:00:00Z Windows Server: EventID=4647 User logoff for user021\",\n",
    "    \"May 18 11:05:12 ubuntu sshd[4000]: session closed for user022\",\n",
    "    \"2025-05-18 11:10:23 macOS loginwindow[6003]: User logout for user user023 (UID 562)\",\n",
    "    \"2025-05-18 11:15:34 Cisco ASA: %ASA-6-722052: VPN Logout: User=user024 IP=192.0.2.202 Duration=00:05:10\",\n",
    "    \"2025/05/18 11:20:45,001801000015,SYSTEM,gplogin,0,2025/05/18 11:20:45,192.0.2.207,10.0.0.2,Logout,globalprotect,user=user026,tunnel=yes\",\n",
    "    '{\"eventTime\":\"2025-05-18T11:25:56Z\",\"eventName\":\"ModifyUser\",\"userIdentity\":{\"type\":\"IAMUser\",\"userName\":\"user027\"},\"sourceIPAddress\":\"192.0.2.208\",\"requestParameters\":{\"groupName\":\"Admins\"}}',\n",
    "    '{\"TimeGenerated\":\"2025-05-18T11:30:07Z\",\"Operation\":\"UserLoggedOut\",\"UserId\":\"user028@example.com\",\"ClientIP\":\"192.0.2.209\"}',\n",
    "    \"timestamp=2025-05-18T11:35:18Z event=logout principal=user029@example.com ip_address=192.0.2.210\",\n",
    "    '{\"published\":\"2025-05-18T11:40:29Z\",\"eventType\":\"user.repository.delete\",\"outcome\":{\"result\":\"SUCCESS\"},\"actor\":{\"displayName\":\"user030\"},\"client\":{\"ipAddress\":\"192.0.2.211\"}}',\n",
    "    \"2025-05-18T11:45:40,user031@example.com,API,updateRecord,login.salesforce.com,Success\",\n",
    "    '{\"CreationTime\":\"2025-05-18T11:50:00\",\"Operation\":\"FileDownloaded\",\"UserId\":\"user032@example.com\",\"ClientIP\":\"192.0.2.212\",\"ItemName\":\"report.pdf\"}',\n",
    "    \"2025-05-18T11:55:00 UTC [3900]: [user033]@hrdb LOG:  statement: SELECT * FROM employees WHERE department='Sales';\",\n",
    "    \"2025-05-18T12:00:00Z 50 Query user034@192.0.2.213 on payrolldb: execute UPDATE payroll SET amount=5000;\",\n",
    "    \"192.0.2.91 - - [18/May/2025:12:05:00 +0000] \\\"GET /api/data HTTP/1.1\\\" 200 1285 \\\"-\\\" \\\"curl/7.68.0\\\"\",\n",
    "    \"2025-05-18 12:10:00 Fortinet FortiGate device_id=FGT002 log_id=0100030001 type=event subtype=system level=notice action=system_reboot_initiated\"\n",
    "]\n",
    "\n",
    "print(\"\\nProcessing new logs...\")\n",
    "processed_logs = onboarder.process_logs(test_logs_bert)\n",
    "print(processed_logs[['raw_log', 'event_type', 'confidence', 'timestamp', 'status']])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
